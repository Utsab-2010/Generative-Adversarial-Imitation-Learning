{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f04b01bd-1af1-49bf-be3c-176da86a9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import d4rl # Import required to register environments\n",
    "# import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2580782-3981-4bcb-9e48-f1f4177bfbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 20.70it/s]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"hopper-expert-v0\")\n",
    "dataset = env.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de952d19-fb43-4aaa-bac4-6021ff32224f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c58dfac-d297-497a-9245-da1c00a81233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.array(dataset[\"rewards\"][:10000])\n",
    "neg_array = data_array[data_array<0]\n",
    "neg_array.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b030a412-c579-4b6f-adef-747325d2b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = torch.tensor(dataset['observations'])[:10000]\n",
    "mean = observations.mean(dim=0)\n",
    "std = observations.std(dim=0)\n",
    "observations = (observations - mean)/std\n",
    "actions = torch.tensor(dataset['actions'])[:10000]\n",
    "# data = TensorPairDataset(observations,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d5d294-d33b-4716-963b-0ad7923b273a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7744,  0.7826,  2.3278,  ...,  0.0355,  0.0036, -0.0113],\n",
       "        [-0.7768,  0.8052,  2.3472,  ...,  0.2680, -0.2564,  0.1914],\n",
       "        [-0.7831,  0.7728,  2.3604,  ...,  0.1356, -0.6247,  0.2166],\n",
       "        ...,\n",
       "        [ 1.3501, -0.4600,  0.7185,  ..., -0.8782,  0.6239,  1.1158],\n",
       "        [ 1.3850, -0.5587,  0.6150,  ..., -1.5694,  0.8177,  1.1408],\n",
       "        [ 1.4168, -0.6333,  0.5020,  ..., -1.1095,  1.2184,  1.2135]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac57a681-8024-45e8-96ef-c44c76661b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25321451e+00, -6.17569933e-04, -2.91591935e-04,  8.43435582e-04,\n",
       "       -1.34866973e-03,  4.22052349e-03,  1.12134418e-03, -3.36745966e-03,\n",
       "       -2.86430993e-03,  2.68016425e-03, -2.46245778e-03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb3a1c0-93db-4653-9338-cf2c6598dc2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_N = {\"observations\":dataset[\"observations\"][:10000],\"actions\":dataset[\"actions\"][:10000]}\n",
    "new_dataset = [dict(zip(dataset_N.keys(), values)) for values in zip(*dataset_N.values())]\n",
    "\n",
    "# Print result\n",
    "# print(new_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36e3831d-5805-446e-ae8a-5274bef8a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_Network(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.network_m = nn.Sequential(nn.Linear(input_size,24),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(24,8),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(8,3))                                     \n",
    "        self.network_s = nn.Sequential(nn.Linear(input_size,24),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(24,8),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(8,3))      \n",
    "    def forward(self,state):\n",
    "        self.mean = self.network_m(state)\n",
    "        self.std = F.softplus(self.network_s(state)) + 1e-6\n",
    "        # print(self.mean,self.std)\n",
    "        \n",
    "        normal_dist = torch.distributions.Normal(self.mean,self.std)\n",
    "        raw_action = normal_dist.rsample()  # Use reparameterization trick\n",
    "        \n",
    "        # Map action to [-1, 1] using tanh\n",
    "        action = torch.clamp(raw_action,min=-1,max=1)\n",
    "        # print(self.mean,self.std)\n",
    "        # Compute log probability of the sampled action\n",
    "        log_prob = normal_dist.log_prob(raw_action) \n",
    "        # print(log_prob)\n",
    "        log_prob = log_prob.sum(dim=-1, keepdim=True)  # Sum over action dimensions\n",
    "        # print(action)\n",
    "        \n",
    "        return action, log_prob\n",
    "\n",
    "        \n",
    "                    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d69899-1a7c-4817-8d73-792ea7480518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d6da081-a3ae-4c66-a13b-e8c7cb495616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_Network(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(D_Network,self).__init__()\n",
    "        self.network = nn.Sequential(nn.Linear(input_size,24),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(24,16),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(16,4),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(4,1),\n",
    "                                     nn.Sigmoid())\n",
    "    def forward(self,state,action):\n",
    "        # print(state,action)\n",
    "        # print(\"State shape:\", state.shape, \"Action shape:\", action.shape)\n",
    "        x = torch.cat((state, action.detach()), dim=-1)\n",
    "        # print(\"combined input\",x)\n",
    "        self.output = self.network(x.float())\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39f677c6-f976-4507-b9ad-f7dd9cf3b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Policy = PM_Network(11,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "993922b8-7156-4fac-a255-5ec9808b40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Discriminator = D_Network(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40d1138f-bfc7-44ca-9bb2-5470429b1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce76a36b-94b8-467f-bc69-d7fbcd1089ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset,epochs,traj_no,max_steps,P_network,D_network,lr_D,lr_P,lamda,opt_func=torch.optim.SGD):\n",
    "    state = torch.from_numpy(env.reset())\n",
    "    # print(state.dtype)\n",
    "    expert_trajectories =[]\n",
    "    for t in range(traj_no):\n",
    "        idx = random.randint(0,len(dataset)-max_steps)\n",
    "        expert_trajectories.append(dataset[idx:idx+max_steps])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch No:\",epoch)\n",
    "        Ex_aD_loss = 0\n",
    "        Ex_eD_loss = 0\n",
    "        Ex_P_loss =0 \n",
    "        Ex_H_loss=0\n",
    "        # Trajectory Sampling\n",
    "        sample_trajectories =[]\n",
    "        for path in range(traj_no):\n",
    "            state = torch.from_numpy(env.reset())\n",
    "            aD_loss=0\n",
    "            eD_loss=0\n",
    "            H_loss=0\n",
    "            current_trajectory=[]\n",
    "            for step in range(1,max_steps):\n",
    "                \n",
    "                action, log_prob = P_network(state.float())\n",
    "                current_trajectory.append({\"state\":state,\"actions\":action,\"log_prob\":log_prob})\n",
    "                temp_action = action\n",
    "                next_state,reward,done,info = env.step(np.array(temp_action.detach()))\n",
    "\n",
    "                exp_state = torch.Tensor(expert_trajectories[path][step][\"observations\"])\n",
    "                exp_action = torch.Tensor(expert_trajectories[path][step][\"actions\"])\n",
    "                \n",
    "                aD_loss += torch.log(D_network(state.detach(),action.detach())+1e-8)\n",
    "                eD_loss += torch.log(1- D_network(exp_state,exp_action)+1e-8)\n",
    "\n",
    "                H_loss-=log_prob*torch.exp(log_prob).item()\n",
    "                \n",
    "                if done or step==max_steps-1:\n",
    "                    # eD_loss /= step\n",
    "                    # aD_loss /= step\n",
    "                    # P_loss /= step\n",
    "                    break\n",
    "                state = torch.from_numpy(next_state)\n",
    "                \n",
    "            sample_trajectories.append(current_trajectory)\n",
    "                    \n",
    "\n",
    "            Ex_aD_loss+=aD_loss\n",
    "            Ex_eD_loss+=eD_loss\n",
    "            Ex_H_loss += H_loss\n",
    "        \n",
    "        ### Updating Discriminator \n",
    "        print(\"XX============UPDATE DISCRIMINATOR===============XX\")\n",
    "        Ex_aD_loss/=traj_no\n",
    "        Ex_eD_loss/=traj_no\n",
    "        total_D_loss = -(Ex_aD_loss + Ex_eD_loss)\n",
    "        \n",
    "        \n",
    "        opt_D = opt_func(D_network.parameters(),lr_D)\n",
    "        # print(Ex_aD_loss,Ex_eD_loss)\n",
    "        print(\"total D loss\",total_D_loss)\n",
    "        # print(list(D_network.parameters()))\n",
    "        total_D_loss.backward()\n",
    "        opt_D.step()\n",
    "        opt_D.zero_grad()\n",
    "\n",
    "        \n",
    "        ## Updating the Policy\n",
    "        print(\"XX================UPDATE POLICY======================XX\")\n",
    "        Ex_P_loss=0\n",
    "        \n",
    "        for traj in sample_trajectories:\n",
    "            traj_P_loss=0\n",
    "            for idx,step in enumerate(traj):\n",
    "                Q=0.1\n",
    "                for jdx in range(idx+1,len(traj)):\n",
    "                    temp = D_network(traj[jdx]['state'].detach(),traj[jdx]['actions'].detach())\n",
    "                    # print(\"temp\",temp)\n",
    "                    Q+=torch.log(temp).item()\n",
    "                    \n",
    "                # print(\"Q:\",Q)\n",
    "                traj_P_loss+=step['log_prob']*Q\n",
    "            \n",
    "            Ex_P_loss+=traj_P_loss\n",
    "        \n",
    "                \n",
    "        Ex_P_loss/=traj_no\n",
    "        # Ex_H_loss/=traj_no\n",
    "        # Ex_H_loss/=traj_no\n",
    "        total_P_loss = (Ex_P_loss) - lamda*Ex_H_loss \n",
    "        print(\"PLOss:\",total_P_loss)\n",
    "        opt_P = opt_func(P_network.parameters(),lr_P)\n",
    "        total_P_loss.backward()\n",
    "        opt_P.step()\n",
    "        opt_P.zero_grad()\n",
    "        print(\"P descent happened!!\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f8c2fd3-2d8a-4d99-a111-feb47660658b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 0\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.9262], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([5.5058], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 1\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6791], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.8863], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 2\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.8402], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([33.2386], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 3\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1113], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7707], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 4\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6183], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4356], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 5\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1543], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.1925], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 6\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0443], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7967], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 7\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4106], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7434], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 8\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0775], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0088], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 9\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4862], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7742], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 10\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3727], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2619], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 11\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2540], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.8995], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 12\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0790], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0821], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 13\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2051], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2233], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 14\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1403], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.8076], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 15\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1481], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7661], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 16\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.2223], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.5353], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 17\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4262], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([0.2480], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 18\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2665], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7963], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 19\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2379], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7861], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 20\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1058], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1696], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 21\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2272], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2859], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 22\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1016], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2241], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 23\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1017], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2025], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 24\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.7290], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([4.8786], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 25\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1975], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4013], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 26\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1032], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.6654], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 27\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1070], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0378], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 28\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5188], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.6248], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 29\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1874], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.3718], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 30\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1375], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.3616], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 31\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1934], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7765], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 32\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5197], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([8.5811], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 33\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0464], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0513], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 34\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0822], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4122], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 35\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0727], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0342], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 36\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1818], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.8417], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 37\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1260], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5243], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 38\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2412], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-0.6577], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 39\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1478], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4043], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 40\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0654], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7787], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 41\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0526], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1559], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 42\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2248], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.9598], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 43\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1084], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9351], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 44\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0857], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3836], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 45\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0538], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5773], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 46\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0810], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3161], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 47\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6140], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1143], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 48\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2701], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.4006], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 49\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0892], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1046], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 50\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2164], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6146], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 51\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2944], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4612], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 52\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1393], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7012], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 53\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0651], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7938], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 54\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.7525], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.3993], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 55\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3387], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2715], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 56\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0799], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1191], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 57\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0385], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2112], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 58\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2074], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0265], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 59\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1028], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2925], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 60\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0456], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7882], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 61\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1022], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0200], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 62\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0473], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5030], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 63\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0972], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8923], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 64\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0724], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3462], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 65\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0428], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9617], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 66\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1079], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6482], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 67\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0682], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3416], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 68\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0682], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7742], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 69\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0324], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4919], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 70\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0630], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7191], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 71\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0475], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6856], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 72\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0426], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4018], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 73\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0495], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1608], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 74\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0676], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2224], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 75\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0830], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7137], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 76\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1341], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.1754], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 77\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0994], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8800], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 78\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0325], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1220], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 79\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0377], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5190], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 80\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5460], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([0.9452], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 81\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1215], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7612], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 82\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1077], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8885], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 83\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0416], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5667], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 84\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0501], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0642], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 85\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1035], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2683], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 86\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0846], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0822], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 87\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0424], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0001], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 88\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0440], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1110], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 89\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0644], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9913], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 90\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0510], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3140], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 91\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0375], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5232], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 92\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0605], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7866], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 93\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0791], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4684], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 94\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0548], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4723], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 95\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1785], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6052], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 96\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0599], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7674], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 97\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0472], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3817], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 98\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0757], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8415], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 99\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0539], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2723], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 100\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0447], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1494], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 101\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0383], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2997], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 102\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1025], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4949], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 103\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0834], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9550], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 104\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0425], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3623], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 105\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0403], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8766], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 106\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0591], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9716], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 107\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1809], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.3332], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 108\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0566], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4343], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 109\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3550], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7711], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 110\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0835], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3251], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 111\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0812], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3053], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 112\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0926], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1536], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 113\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4348], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.2290], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 114\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1533], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1079], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 115\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0433], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2481], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 116\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0935], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7848], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 117\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0477], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3005], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 118\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0730], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9382], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 119\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.9296], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([35.0905], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 120\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3116], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1633], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 121\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1015], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5426], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 122\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0846], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8642], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 123\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0471], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7968], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 124\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0425], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4452], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 125\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0685], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1563], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 126\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0622], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1046], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 127\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1326], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.3128], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 128\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0599], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9788], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 129\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0363], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7009], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 130\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0393], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3341], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 131\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0799], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9188], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 132\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0577], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3381], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 133\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0448], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2271], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 134\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0423], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7329], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 135\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0719], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3096], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 136\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0458], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5213], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 137\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0883], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9410], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 138\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0569], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4867], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 139\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0550], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2481], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 140\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0489], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6000], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 141\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0417], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7820], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 142\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0511], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7738], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 143\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0427], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1974], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 144\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0482], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1583], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 145\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4445], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([4.1599], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 146\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0493], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8765], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 147\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0573], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7821], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 148\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0792], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2625], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 149\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0589], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6143], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 150\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0375], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5419], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 151\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0578], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9812], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 152\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0470], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4678], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 153\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0340], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3888], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 154\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0352], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3775], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 155\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0662], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8891], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 156\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0554], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6362], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 157\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0404], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7616], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 158\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0479], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6677], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 159\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0531], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6944], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 160\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0301], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0448], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 161\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0705], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2163], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 162\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0326], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3533], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 163\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.7471], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([3.4066], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 164\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0853], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3856], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 165\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0344], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2039], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 166\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([3.8215], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([19.1572], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 167\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0709], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5041], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 168\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.7545], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5009], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 169\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1605], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0009], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 170\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0416], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4551], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 171\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2032], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9586], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 172\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4057], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.2074], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 173\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0354], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1471], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 174\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0423], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5385], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 175\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0429], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8609], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 176\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0440], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6859], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 177\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0698], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5658], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 178\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0600], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7398], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 179\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2128], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6390], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 180\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0472], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2022], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 181\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1616], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-0.6744], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 182\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.9186], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([25.9704], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 183\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1116], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0631], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 184\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1072], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0101], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 185\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1176], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3768], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 186\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0484], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3879], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 187\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1154], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9527], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 188\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0575], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2308], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 189\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6823], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.3460], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 190\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0427], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6123], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 191\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0608], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2694], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 192\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2668], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2917], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 193\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.1926], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1235], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 194\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.9902], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2522], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 195\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1951], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7619], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 196\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0547], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3788], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 197\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0584], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8399], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 198\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0822], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7802], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 199\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0661], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4157], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 200\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0670], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0361], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 201\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0630], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1339], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 202\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0418], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7131], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 203\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0468], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6358], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 204\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1606], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.6195], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 205\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0385], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0859], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 206\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0381], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9533], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 207\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0695], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6423], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 208\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1224], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4888], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 209\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0702], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1920], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 210\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0768], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2185], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 211\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0606], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5151], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 212\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0874], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1722], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 213\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0461], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1943], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 214\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0440], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1059], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 215\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0637], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5214], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 216\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0289], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0035], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 217\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0610], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0120], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 218\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.5952], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.8370], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 219\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0829], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6566], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 220\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.3707], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5852], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 221\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0781], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8202], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 222\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0351], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2005], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 223\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0527], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1318], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 224\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0647], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7937], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 225\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0644], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0612], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 226\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0513], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4722], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 227\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0866], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7679], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 228\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.3204], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3260], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 229\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.1995], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([21.9888], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 230\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.5369], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([10.6964], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 231\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0316], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5647], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 232\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0830], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4109], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 233\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0336], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9055], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 234\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0452], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6305], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 235\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0321], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0154], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 236\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0632], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4798], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 237\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0947], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7262], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 238\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0623], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0527], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 239\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0258], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7895], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 240\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0624], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0474], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 241\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0550], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5408], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 242\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0301], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4280], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 243\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0241], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3775], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 244\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0355], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7754], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 245\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([9.2391], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3306], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 246\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([8.1213], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([729.5148], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 247\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([17.0399], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1128], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 248\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([23.0656], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([112.3422], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 249\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([7.9038], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0270], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 250\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([16.1810], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.1411], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 251\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.6279], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.5255], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 252\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.4657], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-0.8858], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 253\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.9556], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.5494], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 254\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5374], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.0665], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 255\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2477], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7825], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 256\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2470], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7900], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 257\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2746], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.8917], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 258\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1873], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.5793], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 259\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1246], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.5841], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 260\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1629], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7659], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 261\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6674], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([2.9267], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 262\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3643], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4800], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 263\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0638], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.5724], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 264\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1451], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4399], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 265\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1018], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.3037], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 266\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1916], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7402], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 267\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1634], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9457], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 268\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0842], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.6806], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 269\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0465], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9635], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 270\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0585], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0499], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 271\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0960], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4787], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 272\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0585], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2197], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 273\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6097], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([3.9730], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 274\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1147], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9584], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 275\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1319], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2214], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 276\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0477], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9409], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 277\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0752], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9623], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 278\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2023], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4811], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 279\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0528], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7003], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 280\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1261], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4681], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 281\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.3306], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([3.0087], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 282\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1302], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.8704], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 283\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0535], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1271], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 284\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1140], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1357], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 285\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6991], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.1251], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 286\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0344], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7503], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 287\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0454], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9116], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 288\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0514], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.8868], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 289\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1653], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4042], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 290\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2664], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1017], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 291\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1349], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1479], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 292\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0486], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0601], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 293\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3028], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([5.8472], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 294\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0685], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0857], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 295\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1007], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4148], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 296\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0780], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1324], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 297\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1564], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.6948], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 298\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0952], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9370], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 299\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0494], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6982], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 300\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0781], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2297], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 301\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1205], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0183], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 302\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0547], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1803], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 303\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0692], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6934], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 304\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0393], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4070], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 305\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0820], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5697], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 306\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0596], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8798], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 307\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0504], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4676], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 308\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0337], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0476], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 309\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0795], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3919], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 310\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0472], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4307], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 311\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0612], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9621], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 312\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1076], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2198], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 313\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0932], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4591], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 314\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0371], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5444], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 315\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2920], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7850], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 316\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1214], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2253], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 317\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0764], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0718], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 318\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3244], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-0.7348], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 319\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1300], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7062], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 320\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0860], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7604], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 321\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1561], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.6514], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 322\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6371], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([6.5303], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 323\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1706], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7497], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 324\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0571], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9371], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 325\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0406], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4785], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 326\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0810], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4744], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 327\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1195], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2418], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 328\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0498], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8498], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 329\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0846], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5088], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 330\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0878], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1952], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 331\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3027], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.9512], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 332\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0374], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4367], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 333\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1561], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1633], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 334\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0962], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0013], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 335\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0920], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.6516], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 336\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0421], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9096], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 337\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0923], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9255], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 338\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0450], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2158], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 339\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0840], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3835], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 340\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0563], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8677], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 341\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.6556], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.0270], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 342\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2722], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9868], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 343\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0763], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0645], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 344\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1093], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6650], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 345\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0720], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5377], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 346\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0939], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2525], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 347\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.8187], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([1.4619], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 348\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0753], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3808], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 349\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0978], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6053], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 350\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1538], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2181], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 351\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0776], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9085], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 352\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0478], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0226], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 353\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0438], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4703], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 354\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1025], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0795], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 355\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0709], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8910], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 356\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0588], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6736], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 357\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0511], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0552], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 358\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0701], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6741], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 359\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0501], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6604], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 360\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1567], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-0.4622], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 361\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0377], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3694], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 362\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0667], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3524], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 363\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0347], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9057], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 364\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0769], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5190], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 365\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0599], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1451], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 366\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0885], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5050], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 367\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0540], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2258], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 368\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0430], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1275], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 369\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0676], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2990], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 370\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0742], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8953], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 371\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0823], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6800], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 372\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0369], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1273], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 373\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0707], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5803], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 374\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0634], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0061], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 375\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0835], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6661], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 376\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0360], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9719], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 377\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0598], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4858], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 378\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2602], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([3.3284], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 379\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0378], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5267], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 380\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0477], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0908], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 381\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0556], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2252], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 382\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0793], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3912], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 383\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1611], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-0.1266], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 384\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0437], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5402], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 385\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0458], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4715], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 386\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0766], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5759], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 387\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0917], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7197], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 388\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0645], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4270], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 389\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0470], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7345], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 390\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0892], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2816], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 391\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0500], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5841], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 392\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0705], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3175], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 393\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0408], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6096], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 394\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0422], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0923], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 395\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0689], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8458], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 396\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0411], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4609], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 397\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0352], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8201], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 398\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0515], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7691], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 399\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0530], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2003], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 400\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0747], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1062], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 401\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0566], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9288], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 402\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0409], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6871], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 403\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0610], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2979], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 404\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0309], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9403], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 405\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0261], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6973], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 406\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0293], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7254], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 407\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0423], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0893], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 408\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0676], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.9550], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 409\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0344], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4996], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 410\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0400], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6423], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 411\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0461], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0612], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 412\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0645], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1909], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 413\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0345], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7738], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 414\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0646], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7598], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 415\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0387], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7614], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 416\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0301], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2899], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 417\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0889], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4889], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 418\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0320], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4435], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 419\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0478], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2363], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 420\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0453], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0440], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 421\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0466], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1774], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 422\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0395], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3595], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 423\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0442], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9473], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 424\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0510], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3604], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 425\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1212], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.0795], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 426\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0422], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7014], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 427\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0333], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8028], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 428\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0536], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0154], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 429\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0556], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9306], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 430\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.0128], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5712], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 431\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5720], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0268], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 432\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0326], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5356], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 433\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0974], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8358], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 434\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0548], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8314], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 435\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0589], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0875], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 436\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0839], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1967], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 437\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0579], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6355], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 438\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3619], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([10.6921], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 439\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0410], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3390], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 440\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0381], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3087], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 441\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0313], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3101], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 442\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2373], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.8452], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 443\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0264], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8571], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 444\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3890], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0608], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 445\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0264], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.6122], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 446\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1774], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7252], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 447\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0397], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3681], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 448\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0590], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6755], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 449\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0977], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2647], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 450\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0480], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1166], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 451\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0323], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6923], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 452\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1978], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3598], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 453\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1716], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3448], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 454\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0874], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9171], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 455\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0636], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0566], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 456\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0753], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7205], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 457\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0521], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2554], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 458\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0391], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1259], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 459\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0532], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1463], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 460\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0331], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6728], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 461\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0483], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0205], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 462\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0423], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1071], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 463\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0689], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9452], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 464\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0578], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8649], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 465\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0479], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4891], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 466\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0609], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2613], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 467\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0421], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8656], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 468\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0433], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2285], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 469\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0330], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6971], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 470\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0656], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0432], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 471\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0643], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1939], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 472\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0612], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6636], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 473\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0374], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2512], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 474\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0549], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6905], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 475\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0430], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0747], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 476\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0640], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8929], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 477\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0273], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5862], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 478\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0480], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0423], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 479\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0750], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1883], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 480\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1040], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4594], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 481\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0675], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1864], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 482\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0587], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3568], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 483\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1094], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4214], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 484\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0583], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5070], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 485\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0249], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4467], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 486\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0326], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1794], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 487\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0317], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2204], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 488\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0456], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0382], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 489\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0389], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3196], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 490\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1329], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.2370], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 491\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0282], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6762], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 492\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0384], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4704], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 493\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0386], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7080], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 494\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0260], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4807], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 495\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0527], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4391], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 496\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0249], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3653], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 497\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0484], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8176], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 498\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3870], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([0.8632], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 499\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0429], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0824], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 500\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0980], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8350], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 501\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.7429], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([51.7026], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 502\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1764], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1342], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 503\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0304], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0660], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 504\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2878], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.3621], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 505\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1499], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4331], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 506\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1062], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7108], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 507\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0324], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1479], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 508\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0346], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3592], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 509\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3339], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.3502], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 510\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0363], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4804], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 511\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1116], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9388], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 512\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0357], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1830], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 513\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1314], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1063], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 514\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0579], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1908], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 515\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1045], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5426], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 516\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0665], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7950], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 517\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0242], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2260], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 518\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0534], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6853], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 519\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0601], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0187], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 520\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0571], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6673], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 521\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0419], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8243], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 522\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0333], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8140], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 523\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0363], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8580], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 524\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0249], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5049], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 525\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0494], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6776], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 526\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0327], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7065], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 527\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3159], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.4168], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 528\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2201], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.0243], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 529\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0657], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0908], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 530\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0374], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1208], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 531\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1066], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4739], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 532\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0571], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0268], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 533\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0642], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5714], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 534\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0395], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2422], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 535\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0634], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.9667], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 536\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0263], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8504], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 537\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0395], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8374], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 538\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0356], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.9546], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 539\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0290], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3616], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 540\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0427], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2903], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 541\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0273], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8106], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 542\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0243], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9662], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 543\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0229], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5546], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 544\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0984], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1751], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 545\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0368], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2701], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 546\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0436], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4807], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 547\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0332], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4824], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 548\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0443], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5716], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 549\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0285], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7226], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 550\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0365], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7686], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 551\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0436], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2398], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 552\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0475], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6106], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 553\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0624], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1549], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 554\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.7400], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9194], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 555\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6144], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1043], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 556\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([3.5662], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([117.3616], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 557\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.0159], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2168], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 558\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0253], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1387], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 559\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0240], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4488], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 560\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0837], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1250], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 561\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0283], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2867], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 562\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0799], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4828], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 563\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1246], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6048], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 564\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0424], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8761], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 565\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0857], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8877], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 566\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0827], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0679], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 567\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0369], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6161], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 568\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0369], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3187], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 569\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0261], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6407], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 570\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0357], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7772], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 571\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0298], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6795], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 572\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0425], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8267], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 573\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0719], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7644], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 574\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0403], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3880], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 575\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0460], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8553], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 576\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0498], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5059], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 577\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0564], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4837], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 578\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0345], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3127], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 579\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0427], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0675], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 580\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1508], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8558], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 581\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0592], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4681], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 582\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0329], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3935], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 583\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0583], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8138], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 584\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1939], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.3326], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 585\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0278], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2337], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 586\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0280], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9930], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 587\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0230], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7995], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 588\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0801], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0159], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 589\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0613], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1004], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 590\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0265], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6698], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 591\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0578], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5397], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 592\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0335], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6963], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 593\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0509], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1635], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 594\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0253], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4804], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 595\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0426], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8819], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 596\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0342], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2047], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 597\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0367], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9911], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 598\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0283], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7135], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 599\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0333], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6042], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 600\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0450], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4148], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 601\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0675], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0945], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 602\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0277], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4074], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 603\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0390], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8392], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 604\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0512], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.4769], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 605\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0455], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5194], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 606\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0728], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5495], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 607\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0331], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5366], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 608\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0270], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5618], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 609\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0352], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8356], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 610\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0317], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0197], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 611\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0560], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5639], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 612\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0361], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1767], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 613\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0435], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6226], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 614\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.9562], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([35.5513], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 615\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0921], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9981], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 616\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0794], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2715], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 617\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0490], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2389], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 618\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0283], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6083], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 619\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0359], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5272], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 620\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0448], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0693], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 621\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0355], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0498], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 622\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0329], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4188], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 623\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0279], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4282], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 624\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0358], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3963], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 625\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0652], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7571], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 626\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0512], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5688], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 627\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([5.9441], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([97.3809], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 628\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.3328], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5640], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 629\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1309], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.6675], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 630\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0732], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0015], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 631\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0745], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.4860], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 632\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1038], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5963], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 633\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0309], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7631], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 634\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0755], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.3760], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 635\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2288], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1359], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 636\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0986], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1279], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 637\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0530], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3420], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 638\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1014], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.1642], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 639\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0584], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0470], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 640\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0681], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5387], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 641\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0334], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3987], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 642\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0598], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5493], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 643\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0346], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0360], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 644\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0508], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2090], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 645\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0519], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1605], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 646\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0350], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8016], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 647\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0467], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6013], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 648\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0531], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3518], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 649\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0244], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6621], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 650\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0400], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3170], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 651\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0254], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2643], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 652\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0355], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5627], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 653\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1948], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.6031], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 654\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0620], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6626], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 655\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0403], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4882], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 656\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0683], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.5036], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 657\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0281], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7188], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 658\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0467], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9026], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 659\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0236], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9615], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 660\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.3401], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([2.4223], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 661\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6043], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7027], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 662\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0422], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2323], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 663\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0913], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7314], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 664\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1558], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.7689], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 665\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0516], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4844], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 666\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0421], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.6529], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 667\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0333], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3384], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 668\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0323], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2848], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 669\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0628], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.6674], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 670\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1541], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8490], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 671\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0568], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4868], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 672\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0410], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5746], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 673\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0286], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9437], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 674\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0275], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4642], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 675\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0301], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0561], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 676\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0892], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8371], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 677\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0256], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1305], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 678\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0357], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9113], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 679\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0540], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1445], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 680\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0306], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1925], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 681\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0361], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6158], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 682\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0274], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1653], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 683\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0627], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9162], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 684\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0473], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1699], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 685\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0511], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9077], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 686\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0354], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0323], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 687\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3593], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.3869], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 688\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0311], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3045], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 689\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0550], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3865], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 690\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0494], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3517], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 691\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0333], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3060], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 692\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.1338], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([73.2383], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 693\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0427], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1871], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 694\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0928], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.5173], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 695\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0852], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5304], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 696\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0528], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7916], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 697\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0492], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2721], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 698\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0239], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7515], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 699\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0462], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0052], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 700\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2587], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.0541], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 701\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1011], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8518], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 702\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0760], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.7043], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 703\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0487], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1640], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 704\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0413], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2957], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 705\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0243], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7497], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 706\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0314], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4074], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 707\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0889], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3771], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 708\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1507], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9429], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 709\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0786], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7322], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 710\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0574], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7275], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 711\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0599], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9265], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 712\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0663], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9039], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 713\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0259], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8529], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 714\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2130], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8087], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 715\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0321], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2017], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 716\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2788], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9400], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 717\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6337], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0981], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 718\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4660], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6601], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 719\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0254], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3011], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 720\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0262], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5017], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 721\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0450], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9735], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 722\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0266], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2076], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 723\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.4286], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.6385], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 724\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0407], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1333], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 725\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.8921], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([75.1730], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 726\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2171], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5524], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 727\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0555], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0562], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 728\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0466], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9664], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 729\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0516], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8634], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 730\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0882], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8573], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 731\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0671], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6093], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 732\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0379], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.6980], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 733\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0234], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7281], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 734\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0304], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9619], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 735\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0239], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.8124], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 736\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.8605], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9304], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 737\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.8117], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9145], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 738\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0177], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0358], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 739\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0654], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.4840], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 740\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.2448], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2798], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 741\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0599], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4844], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 742\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0391], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5090], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 743\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5305], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8350], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 744\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0310], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0977], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 745\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0582], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1494], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 746\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0533], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.8151], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 747\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0362], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5686], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 748\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1878], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-1.7563], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 749\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0614], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6140], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 750\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0587], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0525], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 751\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0570], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4012], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 752\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0428], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9425], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 753\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1607], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2306], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 754\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0629], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.2144], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 755\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0273], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1887], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 756\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0374], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6933], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 757\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.9798], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([55.4259], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 758\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3102], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3673], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 759\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0367], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4141], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 760\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0334], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.4319], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 761\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0384], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1969], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 762\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0279], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6703], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 763\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0312], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3121], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 764\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0335], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.4119], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 765\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0412], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3380], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 766\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0319], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5730], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 767\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0351], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8813], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 768\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0460], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0140], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 769\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1153], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1855], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 770\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1082], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7631], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 771\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0279], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5186], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 772\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0354], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8314], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 773\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0484], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2746], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 774\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0540], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7497], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 775\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0597], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9283], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 776\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1372], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4351], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 777\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0453], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0556], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 778\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0537], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7312], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 779\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0641], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5728], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 780\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3489], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4939], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 781\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0926], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2818], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 782\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0394], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5834], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 783\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0442], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.3441], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 784\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0410], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1367], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 785\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0326], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1405], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 786\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0500], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1219], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 787\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0349], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5818], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 788\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0294], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2828], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 789\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0817], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.1689], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 790\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0317], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2902], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 791\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1561], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7216], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 792\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1034], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9864], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 793\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0499], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6717], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 794\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0701], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.4612], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 795\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0361], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5182], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 796\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0383], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8753], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 797\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.6620], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2680], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 798\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.7617], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([17.7193], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 799\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0293], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0798], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 800\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0294], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3744], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 801\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.7492], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6379], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 802\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.7409], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6633], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 803\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5581], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([5.4893], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 804\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0650], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0005], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 805\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2141], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4302], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 806\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0720], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9192], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 807\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0416], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7174], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 808\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1353], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.0673], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 809\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0317], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6644], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 810\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0513], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5624], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 811\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1632], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9440], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 812\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0848], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0951], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 813\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0546], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5121], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 814\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0382], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7513], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 815\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0344], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5658], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 816\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0457], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.3993], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 817\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0602], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-9.0642], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 818\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0377], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9242], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 819\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0423], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5817], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 820\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0292], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9376], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 821\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2000], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1934], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 822\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0791], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.7239], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 823\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0462], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8048], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 824\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0304], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1345], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 825\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0261], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1328], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 826\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0390], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.3090], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 827\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0319], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5770], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 828\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0341], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9426], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 829\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0292], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0331], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 830\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0410], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8633], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 831\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0277], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6998], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 832\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0279], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.2352], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 833\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0314], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8822], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 834\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0236], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5233], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 835\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0397], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.2688], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 836\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0224], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9240], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 837\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0256], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6680], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 838\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0287], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5150], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 839\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0324], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1136], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 840\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0444], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5764], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 841\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0593], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1854], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 842\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.9679], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([23.6564], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 843\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0650], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-9.2190], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 844\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.9479], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([60.8724], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 845\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.5885], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([23.9130], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 846\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2236], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2018], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 847\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3656], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-10.1251], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 848\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0310], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4410], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 849\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1648], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9942], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 850\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0571], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5708], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 851\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0388], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1188], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 852\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0476], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.3179], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 853\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0319], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0722], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 854\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0352], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4865], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 855\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0441], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0090], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 856\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.1176], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([18.3248], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 857\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1658], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7467], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 858\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0389], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.3943], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 859\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0372], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.2201], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 860\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0696], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.7172], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 861\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0349], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7544], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 862\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0403], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9496], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 863\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0397], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8322], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 864\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0362], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8663], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 865\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0565], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6955], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 866\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0240], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9158], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 867\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0530], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.2173], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 868\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0259], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6272], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 869\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0438], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5045], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 870\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0258], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9866], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 871\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0407], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4614], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 872\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0251], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1714], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 873\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0385], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5015], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 874\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0548], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4716], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 875\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0290], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0114], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 876\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0182], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.2436], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 877\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0441], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.7703], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 878\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0898], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4219], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 879\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0925], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.8893], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 880\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0445], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.6047], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 881\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1202], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-2.7899], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 882\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0507], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8858], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 883\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0450], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4534], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 884\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0339], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9138], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 885\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3417], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.8117], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 886\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0880], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.7179], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 887\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.9030], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([31.6781], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 888\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0732], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8365], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 889\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0450], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1821], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 890\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0651], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0782], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 891\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1747], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1472], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 892\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0379], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5558], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 893\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0281], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0998], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 894\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0425], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0371], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 895\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0603], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0068], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 896\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0421], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8271], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 897\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0542], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0257], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 898\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0433], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6229], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 899\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1532], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0448], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 900\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1332], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7970], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 901\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0273], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1247], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 902\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0315], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3417], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 903\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0434], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0538], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 904\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0330], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.8737], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 905\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0556], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4485], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 906\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0251], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6495], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 907\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2973], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9174], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 908\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0748], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6120], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 909\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0545], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0958], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 910\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0426], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.8020], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 911\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0347], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.2432], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 912\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0562], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5856], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 913\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0903], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4925], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 914\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0544], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.3496], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 915\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0470], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9250], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 916\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0306], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1008], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 917\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0539], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.8480], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 918\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0399], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0756], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 919\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0301], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.1483], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 920\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2459], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.5913], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 921\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0250], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.9455], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 922\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0580], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0732], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 923\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0218], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6316], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 924\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0442], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-9.1204], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 925\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0393], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5811], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 926\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0228], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.4014], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 927\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0283], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5225], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 928\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.8369], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([12.6083], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 929\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0676], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3799], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 930\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0765], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.1041], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 931\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0506], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5627], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 932\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0370], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4793], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 933\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0579], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.1887], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 934\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0415], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1852], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 935\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0392], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.3909], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 936\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1488], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.8273], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 937\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.9068], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.4209], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 938\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([2.2668], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3500], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 939\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.7108], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.7481], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 940\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0521], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.6764], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 941\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0266], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4860], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 942\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1811], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-9.3300], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 943\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1492], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.9971], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 944\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0796], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5849], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 945\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0391], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9247], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 946\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5095], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([39.7233], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 947\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0323], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6812], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 948\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0298], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1530], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 949\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0381], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.3169], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 950\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0257], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9138], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 951\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([1.2034], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([12.0596], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 952\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0875], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.4370], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 953\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0341], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-9.5115], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 954\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0156], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3952], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 955\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0262], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6376], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 956\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0247], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.6997], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 957\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0812], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.5234], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 958\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0388], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.6149], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 959\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.8586], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([0.9529], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 960\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3284], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0947], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 961\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0195], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.4201], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 962\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0241], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.9102], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 963\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0258], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5047], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 964\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0381], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.3104], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 965\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1574], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.9138], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 966\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0454], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.1508], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 967\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0414], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.3653], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 968\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0361], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.7318], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 969\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0315], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0271], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 970\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0227], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3205], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 971\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.8540], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-3.1494], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 972\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.2489], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0936], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 973\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0221], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8811], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 974\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0325], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.1293], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 975\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0332], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.7811], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 976\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0195], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.8251], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 977\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0267], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0977], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 978\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0197], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5350], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 979\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.8443], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-4.3193], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 980\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0250], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.1293], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 981\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0282], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.0841], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 982\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0885], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0199], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 983\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1792], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-9.2103], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 984\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0356], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.0344], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 985\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.5851], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-0.6053], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 986\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1489], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.7276], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 987\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0734], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-10.0886], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 988\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0425], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-8.2434], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 989\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.3708], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.0800], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 990\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1018], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.3911], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 991\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0453], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.2060], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 992\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0294], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0108], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 993\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0252], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.6574], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 994\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1774], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.5266], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 995\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0575], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.2530], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 996\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0304], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.0490], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 997\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0358], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-5.5640], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 998\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.1073], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-6.8814], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n",
      "Epoch No: 999\n",
      "XX============UPDATE DISCRIMINATOR===============XX\n",
      "total D loss tensor([0.0554], grad_fn=<NegBackward0>)\n",
      "XX================UPDATE POLICY======================XX\n",
      "PLOss: tensor([-7.2971], grad_fn=<SubBackward0>)\n",
      "P descent happened!!\n"
     ]
    }
   ],
   "source": [
    "train(new_dataset,1000,10,300,Policy,Discriminator,1e-2,1e-4,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18afbaaf-d056-4e1f-89c7-31e6a802fc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (3,), float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2dd299ca-e6bb-4e25-abe8-27bb89f21869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,D_network,episodes):\n",
    "    env = gym.make(\"hopper-expert-v0\")\n",
    "    # state,info = env.reset()\n",
    "    state = torch.from_numpy(env.reset())\n",
    "    total_reward=0\n",
    "    D_loss =0\n",
    "    for ep in range(episodes):\n",
    "       \n",
    "        action, log_prob = model(state.float())\n",
    "        temp_action = action\n",
    "        next_state,reward,done,info = env.step(np.array(temp_action.detach()))\n",
    "        D_loss += torch.log(D_network(state.detach(),action.detach())+1e-8).item()\n",
    "        total_reward+=reward\n",
    "        if done or ep==episodes-1:\n",
    "            print(total_reward,ep)\n",
    "            \n",
    "            break\n",
    "        state = torch.from_numpy(next_state)    \n",
    "    env.close()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e20af6c1-8412-425c-983b-e6cbafe52782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.57709301866323 23\n",
      "14.466346758039528 13\n",
      "9.779312991876495 10\n",
      "27.64620641131927 20\n",
      "51.97627950294407 32\n",
      "78.16934138050617 45\n",
      "18.468441769378337 16\n",
      "8.487149214471435 9\n",
      "11.190734372356312 11\n",
      "45.022729112489856 29\n",
      "61.31305821549223 37\n",
      "11.630042866038364 12\n",
      "28.379293102121956 20\n",
      "13.552582965274434 14\n",
      "79.86950409393887 46\n",
      "12.769618118339555 12\n",
      "17.666498141186665 15\n",
      "29.55951194911984 21\n",
      "19.697407015938083 17\n",
      "49.791305938772 31\n",
      "13.62416783223052 13\n",
      "13.751882832143227 12\n",
      "38.74946843325119 25\n",
      "13.948307220488738 13\n",
      "13.973097702558933 13\n",
      "30.907398301713858 22\n",
      "14.527180289612867 13\n",
      "38.214483351258544 25\n",
      "22.042893814770174 17\n",
      "72.38385357734451 42\n",
      "50.721726931501266 31\n",
      "25.177513888226063 19\n",
      "12.354589966583006 12\n",
      "37.93778959326777 27\n",
      "25.188987710460783 18\n",
      "14.032852514129575 12\n",
      "11.692090028079726 11\n",
      "21.245697682440145 17\n",
      "10.085791288160289 10\n",
      "21.032111325634474 18\n",
      "76.32186170644914 44\n",
      "79.6138749330847 46\n",
      "35.26249585486835 25\n",
      "15.139350682278305 14\n",
      "9.253079122078477 9\n",
      "7.286200755298724 8\n",
      "78.16516803698534 45\n",
      "41.022935001004214 26\n",
      "12.59914110365535 12\n",
      "17.10750044624671 15\n",
      "12.527250609892484 12\n",
      "11.247185660708487 11\n",
      "27.972971114292513 21\n",
      "7.219572175314556 8\n",
      "16.60252969620063 14\n",
      "35.44689389405327 25\n",
      "20.27205420614022 16\n",
      "35.42981697189591 23\n",
      "21.865202383982844 17\n",
      "27.326795106798816 18\n",
      "26.07614913575047 19\n",
      "63.09687688870074 37\n",
      "46.38790821873642 29\n",
      "23.199830043536885 18\n",
      "33.588705522136 25\n",
      "13.496713905391008 12\n",
      "14.60721872248454 13\n",
      "14.134896370346222 13\n",
      "41.40226822066728 27\n",
      "21.38328310353765 17\n",
      "14.235984794368047 12\n",
      "21.441591209598815 16\n",
      "46.01525548306364 29\n",
      "22.45232145493106 17\n",
      "33.76673292912707 23\n",
      "26.282117650560835 19\n",
      "13.261741822128105 12\n",
      "8.931448418833531 9\n",
      "18.21570533730012 16\n",
      "18.20811237405927 15\n",
      "18.97971509689861 16\n",
      "22.184630514975147 17\n",
      "17.489374367349757 14\n",
      "74.49265806811904 44\n",
      "36.21611125645117 24\n",
      "10.477867059428151 11\n",
      "15.164749915009741 14\n",
      "30.352215679285237 20\n",
      "11.95513281324104 12\n",
      "15.96059938080744 13\n",
      "8.212487088465355 9\n",
      "12.543965242430486 12\n",
      "39.79762746701672 26\n",
      "17.601625773731506 15\n",
      "14.444920356729993 12\n",
      "8.809835729969711 9\n",
      "14.937536031937766 13\n",
      "11.536870280893059 11\n",
      "14.280914277036171 13\n",
      "18.680491619701506 15\n",
      "20.792773285285243 16\n",
      "78.05944295472727 44\n",
      "12.352259020511102 12\n",
      "18.712780694632247 17\n",
      "83.01543668887095 47\n",
      "11.035689920316647 11\n",
      "10.90830819906918 11\n",
      "34.280756926111955 23\n",
      "14.098307147758666 13\n",
      "12.557223760888975 12\n",
      "52.201066790349245 33\n",
      "10.807579970298681 11\n",
      "64.47930498427914 38\n",
      "113.32345075072887 61\n",
      "13.975622140315865 13\n",
      "61.50702456124344 36\n",
      "15.025683503968429 14\n",
      "24.98963055388753 18\n",
      "14.162666437741064 13\n",
      "12.075068832676076 11\n",
      "16.234573049088027 15\n",
      "28.95916169497536 20\n",
      "10.78152076063883 11\n",
      "30.333429767584995 21\n",
      "10.147292691740649 10\n",
      "26.169965969523705 19\n",
      "72.84165340312305 42\n",
      "12.224089675290038 12\n",
      "26.98054811783266 19\n",
      "20.935094788161233 16\n",
      "12.581637844993388 12\n",
      "30.43658859098554 23\n",
      "65.65145830831928 39\n",
      "14.830628159351967 13\n",
      "14.833755372146925 14\n",
      "11.135059414321828 11\n",
      "11.671054525006847 11\n",
      "73.12858847224908 43\n",
      "13.127934230702635 12\n",
      "9.990268894794387 10\n",
      "44.69401429522021 28\n",
      "11.757761279913645 12\n",
      "31.382361152213868 23\n",
      "71.28158077405575 42\n",
      "18.542949169514777 15\n",
      "26.380231252495577 20\n",
      "32.45857829047451 23\n",
      "22.672929255823448 18\n",
      "19.086349269344424 15\n",
      "18.53372402505544 16\n",
      "133.96973717305494 68\n",
      "46.17417599302652 29\n",
      "76.87859134285517 45\n",
      "31.20100241783087 22\n",
      "47.1876855860003 30\n",
      "100.08459531575876 56\n",
      "30.892818581283084 23\n",
      "14.167367836306726 13\n",
      "13.168005278835064 12\n",
      "53.10047387819513 33\n",
      "29.436888130883546 21\n",
      "19.270740675898644 16\n",
      "67.30741515657827 40\n",
      "15.459761197119908 14\n",
      "11.497317006563936 11\n",
      "25.8557347339124 20\n",
      "10.812390346320678 10\n",
      "41.661472750674925 26\n",
      "19.333193223823514 16\n",
      "26.760650314884764 20\n",
      "20.784787112031445 17\n",
      "14.324767154619227 13\n",
      "7.642672083870953 8\n",
      "94.61079352559246 54\n",
      "26.833462077367674 20\n",
      "26.04772756070087 19\n",
      "14.263603208813292 13\n",
      "17.16641413732165 14\n",
      "25.54181271428153 19\n",
      "55.92604262977836 34\n",
      "49.984247055172844 31\n",
      "73.31774351813685 43\n",
      "32.23982451133141 24\n",
      "12.502306572003912 12\n",
      "30.896416941652138 22\n",
      "18.843588692901484 15\n",
      "15.151864439677073 13\n",
      "101.19825617574422 56\n",
      "22.94293035721472 17\n",
      "13.550669744619995 13\n",
      "55.62863857345687 34\n",
      "34.82908345026291 24\n",
      "39.44960190682168 25\n",
      "18.64907808031287 17\n",
      "14.186276040088599 13\n",
      "13.776283710579046 13\n",
      "38.48161207667849 26\n",
      "9.475763838314277 10\n",
      "7.634445911702899 8\n",
      "6.781782428898971 7\n"
     ]
    }
   ],
   "source": [
    "gail_history=[]\n",
    "for i in range(200):\n",
    "    gail_history.append(test(Policy,Discriminator,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15fb9de8-7edf-475c-b88e-a87fdc80716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Policy_random = PM_Network(11,3)\n",
    "D_random = D_Network(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de4b08d8-ce81-4623-bf24-d92dd584ac4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.380378169225962 15\n",
      "22.25904126546317 19\n",
      "8.373898183845345 13\n",
      "22.60281498706211 21\n",
      "9.003813405780713 12\n",
      "17.361818039670876 18\n",
      "14.406869783382787 17\n",
      "6.354273726495643 8\n",
      "5.177576847838792 10\n",
      "21.89171700532268 20\n",
      "13.571689161930907 17\n",
      "6.63302851215146 12\n",
      "9.276817610038243 11\n",
      "14.611724300329701 15\n",
      "11.832323193414119 13\n",
      "33.866113778422616 29\n",
      "12.853511860295344 13\n",
      "7.211701569972553 12\n",
      "54.92919250982098 32\n",
      "9.79362094990014 15\n",
      "22.64427558502534 20\n",
      "58.356064771356316 43\n",
      "44.82467437384147 32\n",
      "12.115785746657306 15\n",
      "52.75168796709531 38\n",
      "10.592681978103636 16\n",
      "22.193173887899995 20\n",
      "20.180032396999223 22\n",
      "6.801158813658163 10\n",
      "10.685329620634597 12\n",
      "8.837058877505008 11\n",
      "15.162614281200357 22\n",
      "25.613177478151837 26\n",
      "8.029703717910737 13\n",
      "15.852939801970068 21\n",
      "12.328699150102214 14\n",
      "10.22496140577917 13\n",
      "63.05105985681353 41\n",
      "9.436808727852982 12\n",
      "21.59065556079693 19\n",
      "8.703870114057223 13\n",
      "21.20025012872751 24\n",
      "10.357637133301708 12\n",
      "14.906478781530282 16\n",
      "18.090827347288865 19\n",
      "12.816046154367067 17\n",
      "9.432342366305456 12\n",
      "7.907011792399937 12\n",
      "13.17044130388457 17\n",
      "11.926901416987707 13\n",
      "7.678465184094582 10\n",
      "15.534486108738687 17\n",
      "29.147786686614502 25\n",
      "14.22260454951832 15\n",
      "12.102654809895387 13\n",
      "7.050383069687164 11\n",
      "10.862913678186894 13\n",
      "10.452583398533935 14\n",
      "8.110024023569482 10\n",
      "8.94456346455028 14\n",
      "6.5801840742329905 9\n",
      "20.222419584292705 22\n",
      "36.105361658546414 27\n",
      "13.57073734427798 13\n",
      "42.73384731811658 33\n",
      "10.968340730708734 12\n",
      "20.79772902499625 22\n",
      "13.352972346328016 17\n",
      "19.942223314368036 20\n",
      "14.54430703128134 17\n",
      "9.116060079436412 11\n",
      "17.314185814248013 17\n",
      "24.182315898280415 21\n",
      "7.401315278269075 10\n",
      "13.662905201159838 16\n",
      "12.01001801727327 14\n",
      "19.548722589471772 19\n",
      "12.022959605778917 19\n",
      "7.634362525586389 12\n",
      "57.35560663515742 38\n",
      "12.794023756845538 16\n",
      "11.10160174324391 13\n",
      "9.518981910135007 13\n",
      "11.606499998917542 17\n",
      "11.870007476634152 16\n",
      "16.79446308877386 17\n",
      "7.896488599960588 10\n",
      "64.96814683043847 46\n",
      "10.444697143683737 17\n",
      "6.8628047723830035 9\n",
      "20.62161788362285 20\n",
      "5.929126749067637 13\n",
      "42.81299229037036 32\n",
      "14.28370141157214 15\n",
      "9.404575466762001 15\n",
      "22.15039353454648 22\n",
      "21.17922428852444 20\n",
      "8.994864825910145 13\n",
      "11.071411850736473 14\n",
      "13.07849524822935 14\n",
      "23.85872387207105 28\n",
      "10.725813372958186 16\n",
      "15.35364661300084 17\n",
      "29.602526704729105 24\n",
      "22.50954251618641 23\n",
      "7.757460419279781 16\n",
      "10.557215414985063 15\n",
      "14.715748428175276 17\n",
      "12.542876402449915 13\n",
      "14.503794962115537 16\n",
      "8.29626182936515 12\n",
      "13.391824698243935 15\n",
      "10.771016330583064 15\n",
      "14.549350198840727 14\n",
      "10.013692597228756 12\n",
      "12.722643306336998 15\n",
      "8.78706326170973 11\n",
      "5.531826877177897 8\n",
      "6.470435157130461 11\n",
      "27.82106868496389 30\n",
      "15.207414293720209 16\n",
      "9.887627023968086 12\n",
      "16.139774103280377 15\n",
      "8.666269512098102 11\n",
      "7.911053437741744 10\n",
      "14.067312003228846 15\n",
      "7.832026298518835 11\n",
      "7.827387672564615 12\n",
      "10.155507427405395 17\n",
      "21.548685501170848 20\n",
      "12.594656623790593 18\n",
      "11.35925256542499 13\n",
      "37.41178088643589 30\n",
      "21.086086198266806 19\n",
      "8.044054598440427 11\n",
      "16.184672344044824 16\n",
      "18.697941868009515 24\n",
      "7.780248709819755 9\n",
      "81.43101615305824 52\n",
      "13.387415733139566 17\n",
      "11.809049861984134 14\n",
      "5.851696907930357 7\n",
      "64.8218966279225 42\n",
      "12.647007794646514 16\n",
      "5.8963859002447725 8\n",
      "12.35336682787194 20\n",
      "21.189125057017844 19\n",
      "9.96379068999552 12\n",
      "10.454549934964627 15\n",
      "10.1337550404488 14\n",
      "7.066953727960315 10\n",
      "16.42809514512049 19\n",
      "11.54315351840957 14\n",
      "12.85086433341036 14\n",
      "7.720622980588243 10\n",
      "9.43297156559514 13\n",
      "26.686479630127486 23\n",
      "16.106239755692847 17\n",
      "10.588536906134687 12\n",
      "20.426023563933956 20\n",
      "5.840852223149092 8\n",
      "10.994925171175966 16\n",
      "8.161744302756064 11\n",
      "9.73084960558769 12\n",
      "6.924913822496629 10\n",
      "5.846512528437207 11\n",
      "98.65333323472554 55\n",
      "15.546027146901311 18\n",
      "12.60986029143195 16\n",
      "6.278216389784244 8\n",
      "7.083090104430555 11\n",
      "42.730220622319955 39\n",
      "13.109476921434707 16\n",
      "12.04332371392422 14\n",
      "9.241519830050741 12\n",
      "27.977486152907137 27\n",
      "7.065283057658887 9\n",
      "14.0582480988483 18\n",
      "23.475862161276343 24\n",
      "9.308871604258758 13\n",
      "13.858691826412143 14\n",
      "14.406955686238403 17\n",
      "22.890870589635213 25\n",
      "77.65668454098031 49\n",
      "17.117222629699008 17\n",
      "16.32212784368605 17\n",
      "45.3891350056477 32\n",
      "10.979233516759082 12\n",
      "15.208601063359803 15\n",
      "21.647887234917448 21\n",
      "15.230199954465897 17\n",
      "16.18582147334969 19\n",
      "9.728583138982739 13\n",
      "22.59228682953213 21\n",
      "9.955369917283035 14\n",
      "10.942527075937198 15\n",
      "19.486275177245158 21\n",
      "17.88503275802876 18\n",
      "17.12318429316088 19\n",
      "14.121759207822365 16\n"
     ]
    }
   ],
   "source": [
    "random_history=[] \n",
    "for i in range(200):\n",
    "    random_history.append(test(Policy_random,D_random,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ffe32258-e102-46ba-8c03-7be724fea02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "def plot_two_series(y1, y2, x_label='Episodes', y_label='Total Reward', title='Graph of Two Series', legend1='Gail', legend2='No Gail'):\n",
    "    x = range(len(y1))  # Assumes y1 and y2 have the same length\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    window_size=5\n",
    "    smoothed_y1 = moving_average(y1, window_size)\n",
    "    smoothed_y2 = moving_average(y2, window_size)\n",
    "    x_smooth = range(window_size - 1, len(y1))  # Adjust x for smoothed data\n",
    "    \n",
    "    plt.plot(x_smooth, smoothed_y1, label=f'{legend1} (SMA-{window_size})', color='blue', linewidth=2)\n",
    "    plt.plot(x_smooth, smoothed_y2, label=f'{legend2} (SMA-{window_size})', color='orange', linewidth=2)\n",
    "    # plt.plot(x, y1, label=legend1, marker='o')\n",
    "    # plt.plot(x, y2, label=legend2, marker='x')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7932d6d5-1463-4bd9-9b82-72f079312cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_two_series(gail_history,random_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6875b-26ab-49cf-8ede-30c10e5389a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f4d17-0100-4aa0-a2f4-fdb3aef8c0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad8d20-da06-4fc6-aade-38cfbd5bc1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1a7c5-8153-42aa-be25-7b71714b0234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRL_AGV",
   "language": "python",
   "name": "irl_agv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
